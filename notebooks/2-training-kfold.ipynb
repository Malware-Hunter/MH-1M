{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as dataframe\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# import shap\n",
    "\n",
    "import xgboost\n",
    "print(xgboost.__version__)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "\n",
    "!export PYTHONPATH=\"/home/hendrio/amex-1M/:$PYTHONPATH\"\n",
    "!export PYTHONPATH=\"/home/hendrio/amex-1M/src/:$PYTHONPATH\"\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/hendrio/amex-1M/')\n",
    "sys.path.append('/home/hendrio/amex-1M/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/hendrio/amex-1M/\"\n",
    "os.listdir(base_dir)\n",
    "\n",
    "paths={\n",
    "    'data': join(base_dir, 'data'),\n",
    "    'src': join(base_dir, 'data', 'src'),\n",
    "    'processed': join(base_dir, 'data', 'processed'),\n",
    "    'datasets': join(base_dir, 'datasets1'),\n",
    "    'results': join(base_dir,'results'),\n",
    "    'images': join(base_dir,'images'),\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_amex_1m(path, file_name='amex-1M_binary-dataset-[intents-permissions-apicalls].npz'):\n",
    "    data = np.load(join(path, file_name), allow_pickle=True)\n",
    "    metadata = dataframe(data['metadata'], columns=data['metadata_columns'])\n",
    "    \n",
    "    columns_names = data['column_names']\n",
    "    sha256 = data['sha256']\n",
    "\n",
    "    labels_ohe = OneHotEncoder().fit_transform(np.expand_dims(metadata['CLASS'].values, axis=1)).toarray()\n",
    "\n",
    "    print(data['data'].shape, labels_ohe.shape)\n",
    "\n",
    "    # if (\"CLASS\" not in metadata.columns):\n",
    "    #     print()\n",
    "    #     metadata['CLASS'] = create_class(df=metadata['VT_SCANNERS_MALICIOUS'], threshold=4)\n",
    "    \n",
    "    print(metadata['CLASS'].value_counts())\n",
    "    return data['data'], labels_ohe, metadata, columns_names, sha256\n",
    "\n",
    "\n",
    "def create_class(df, threshold):\n",
    "    return np.asarray([1 if i>=threshold else 0 for i in df ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'amex-1M-[intents-permissions-opcodes-apicalls]-chi2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340515, 12409) (1340515, 2)\n",
      "CLASS\n",
      "0    1221421\n",
      "1     119094\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data, labels_ohe, metadata, columns_names, sha256 = load_amex_1m(\n",
    "    path=paths['processed'], \n",
    "    file_name=f'{dataset_name}.npz'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.base import clone\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import trainer\n",
    "\n",
    "def stratified_k_fold_evaluation(model, data, labels_ohe, k=10, path_save=None, dir_name=None):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=0)\n",
    "    confusion_matrices, classification_reports = [], []\n",
    "    folds_report, cm_report = {}, {}\n",
    "    best_model, best_train_index, best_test_index = None, None, None\n",
    "    best_score = 0\n",
    "    fold = 1\n",
    "\n",
    "    if path_save is not None:\n",
    "        if dir_name is None:\n",
    "            raise Exception(\"Provid a 'dir_name' parameter to save results. \")\n",
    "        \n",
    "        os.makedirs(join(path_save, dir_name), exist_ok=True)\n",
    "        os.makedirs(join(path_save, dir_name, 'KFold'), exist_ok=True)\n",
    "\n",
    "    for train_index, test_index in skf.split(data, np.argmax(labels_ohe, axis=1)):\n",
    "        print(f'fold {fold}')\n",
    "        X_train, X_test = data[train_index], data[test_index]\n",
    "        y_train, y_test = labels_ohe[train_index], labels_ohe[test_index]\n",
    "\n",
    "        # Clone the model to ensure a fresh model for each fold\n",
    "        model_fold = clone(model)\n",
    "        model_fold.fit(X_train, y_train)\n",
    "        y_pred = model_fold.predict(X_test)\n",
    "\n",
    "        # Calculate confusion matrix and classification report\n",
    "        cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "        report = classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1), output_dict=True)\n",
    "        print(cm)\n",
    "        print(report)\n",
    "        confusion_matrices.append(cm)\n",
    "        classification_reports.append(report)\n",
    "        folds_report[f'fold-{fold}'] = report\n",
    "        cm_report[f'fold-{fold}'] = cm.tolist()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1))\n",
    "\n",
    "        # Check if the current fold model is the best so far\n",
    "        if accuracy > best_score:\n",
    "            best_score = accuracy\n",
    "            best_model = clone(model_fold)\n",
    "            best_train_index = train_index\n",
    "            best_test_index = test_index\n",
    "        \n",
    "        fold += 1\n",
    "\n",
    "    # Save the best model to a file\n",
    "    os.makedirs(os.path.join(path_save, dir_name), exist_ok=True)\n",
    "    joblib.dump(best_model, os.path.join(path_save, dir_name, 'XGBClassifier.pkl'))\n",
    "    print(f\"Best model saved with accuracy: {best_score}\")\n",
    "\n",
    "    # Save the train and test indices of the best fold\n",
    "    np.save(os.path.join(path_save, dir_name, 'best_train_index.npy'), best_train_index)\n",
    "    np.save(os.path.join(path_save, dir_name, 'best_test_index.npy'), best_test_index)\n",
    "\n",
    "    with open(join(path_save, dir_name, 'KFold', f'classification_report_folds.json'), 'w') as f:\n",
    "        json.dump(folds_report, f, indent=4)\n",
    "\n",
    "    with open(join(path_save, dir_name, 'KFold', f'cm_folds.json'), 'w') as f:\n",
    "        json.dump(cm_report, f, indent=4)\n",
    "\n",
    "    # Aggregate confusion matrices and classification reports\n",
    "    # final_confusion_matrix = np.mean(confusion_matrices, axis=0)\n",
    "    # Using SUM\n",
    "    final_confusion_matrix = np.sum(confusion_matrices, axis=0)\n",
    "\n",
    "    print(f'confusion matrix for fold {fold}')\n",
    "    print(final_confusion_matrix)\n",
    "    \n",
    "    trainer.plot_confusion_matrix(\n",
    "        final_confusion_matrix, \n",
    "        class_labels=['Benign', 'Malware'], \n",
    "        path_save=os.path.join(path_save, dir_name, f'{dir_name}-confusion_matrix')\n",
    "        )\n",
    "\n",
    "    final_classification_report = {}\n",
    "\n",
    "    # Calculate mean and confidence intervals for each metric\n",
    "    for key in classification_reports[0].keys():\n",
    "        metrics = [report[key] for report in classification_reports]\n",
    "        if isinstance(metrics[0], dict):  # Handle nested dicts for per-class metrics\n",
    "            final_classification_report[key] = {}\n",
    "            for metric in metrics[0].keys():\n",
    "                \n",
    "                if metric==\"support\": ## does not aggregate support information\n",
    "                    continue\n",
    "\n",
    "                values = [m[metric] for m in metrics]\n",
    "                mean = np.mean(values)\n",
    "                std_dev = np.std(values)\n",
    "                conf_int = stats.t.interval(0.95, len(values)-1, loc=mean, scale=stats.sem(values))\n",
    "                margin = conf_int[1] - mean\n",
    "                final_classification_report[key][metric] = {\n",
    "                    'mean': mean,\n",
    "                    'std_dev': std_dev,\n",
    "                    '95% CI': conf_int,\n",
    "                    'margin': margin\n",
    "                }\n",
    "        else:\n",
    "            values = metrics\n",
    "            mean = np.mean(values)\n",
    "            std_dev = np.std(values)\n",
    "            conf_int = stats.t.interval(0.95, len(values)-1, loc=mean, scale=stats.sem(values))\n",
    "            margin = conf_int[1] - mean\n",
    "            final_classification_report[key] = {\n",
    "                'mean': mean,\n",
    "                'std_dev': std_dev,\n",
    "                '95% CI': conf_int,\n",
    "                'margin': margin\n",
    "            }\n",
    "    if path_save is not None:\n",
    "        # Save final aggregated results\n",
    "        pd.DataFrame(final_confusion_matrix).to_csv(join(path_save, dir_name,'final_confusion_matrix.csv'))\n",
    "        pd.DataFrame(final_classification_report).to_csv(join(path_save, dir_name,'final_classification_report.csv'))\n",
    "        with open(os.path.join(path_save, f'{dir_name}-report.json'), 'w') as f:\n",
    "            json.dump(final_classification_report, f, indent=4)\n",
    "\n",
    "    return final_confusion_matrix, final_classification_report\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# model = RandomForestClassifier()\n",
    "# data = np.random.rand(100, 10)  # Example data\n",
    "# labels_ohe = np.eye(3)[np.random.choice(3, 100)]  # Example one-hot encoded labels\n",
    "# stratified_k_fold_evaluation(model, data, labels_ohe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amex-1M-[intents-permissions-opcodes-apicalls]-chi2\n"
     ]
    }
   ],
   "source": [
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1340515, 12409) (1340515, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, labels_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n",
      "[[121523    620]\n",
      " [  1390  10519]]\n",
      "{'0': {'precision': 0.9886911880761189, 'recall': 0.9949239825450497, 'f1-score': 0.9917977931574824, 'support': 122143.0}, '1': {'precision': 0.9443397073345902, 'recall': 0.8832815517675707, 'f1-score': 0.9127906976744186, 'support': 11909.0}, 'accuracy': 0.9850058186375437, 'macro avg': {'precision': 0.9665154477053546, 'recall': 0.9391027671563101, 'f1-score': 0.9522942454159504, 'support': 134052.0}, 'weighted avg': {'precision': 0.9847510619746743, 'recall': 0.9850058186375437, 'f1-score': 0.9847789086939324, 'support': 134052.0}}\n",
      "fold 2\n"
     ]
    }
   ],
   "source": [
    "stratified_k_fold_evaluation(\n",
    "    model=XGBClassifier(random_state=0), \n",
    "    data=data, \n",
    "    labels_ohe=labels_ohe, \n",
    "    k=10, \n",
    "    path_save=join(paths['results'], 'models'), \n",
    "    dir_name=f'{dataset_name}-XGBClassifier-KFold10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
